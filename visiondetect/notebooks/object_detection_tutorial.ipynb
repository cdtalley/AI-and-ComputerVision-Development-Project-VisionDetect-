{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VisionDetect: Object Detection with Deep Learning\n",
    "\n",
    "This notebook demonstrates how to use the VisionDetect framework for object detection tasks. We'll cover:\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Loading and preprocessing data\n",
    "3. Creating and training a model\n",
    "4. Evaluating model performance\n",
    "5. Making predictions on new images\n",
    "6. Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's import the necessary modules and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Import VisionDetect modules\n",
    "from src.data.preprocessing import DataProcessor\n",
    "from src.models.architecture import ObjectDetectionModel\n",
    "from src.models.trainer import ModelTrainer\n",
    "from src.models.predictor import Predictor\n",
    "from src.utils.visualization import visualize_detection, plot_training_metrics\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "Next, we'll set up our data processing pipeline. For this example, we'll use a small dataset of images with object annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create data directories if they don't exist\n",
    "data_dir = project_root / \"data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Initialize data processor\n",
    "processor = DataProcessor(\n",
    "    data_dir=data_dir,\n",
    "    img_size=(640, 640),\n",
    "    batch_size=4,  # Small batch size for demonstration\n",
    "    num_workers=2,\n",
    "    augment=True\n",
    ")\n",
    "\n",
    "# Prepare dataset\n",
    "# Note: In a real scenario, you would have your dataset ready or use the download option\n",
    "dataloaders = processor.prepare_dataset(download=False)\n",
    "\n",
    "# Print dataset information\n",
    "for split, dataloader in dataloaders.items():\n",
    "    print(f\"{split} dataset: {len(dataloader.dataset)} samples, {len(dataloader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Data\n",
    "\n",
    "Let's visualize some samples from our dataset to understand what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get a batch of training data\n",
    "if 'train' in dataloaders:\n",
    "    batch = next(iter(dataloaders['train']))\n",
    "    images = batch['images']\n",
    "    targets = batch['targets']\n",
    "    \n",
    "    # Display a few images with their bounding boxes\n",
    "    fig, axs = plt.subplots(1, min(4, len(images)), figsize=(15, 5))\n",
    "    if len(images) == 1:\n",
    "        axs = [axs]\n",
    "    \n",
    "    for i, (image, target) in enumerate(zip(images[:4], targets[:4])):\n",
    "        # Convert tensor to numpy array and denormalize\n",
    "        img = image.permute(1, 2, 0).cpu().numpy()\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        img = (img * std + mean) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        \n",
    "        # Display image\n",
    "        axs[i].imshow(img)\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        boxes = target['boxes'].cpu().numpy()\n",
    "        labels = target['labels'].cpu().numpy()\n",
    "        \n",
    "        for box, label in zip(boxes, labels):\n",
    "            x1, y1, x2, y2 = box\n",
    "            rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, fill=False, edgecolor='red', linewidth=2)\n",
    "            axs[i].add_patch(rect)\n",
    "            axs[i].text(x1, y1, f\"Class {label}\", color='white', backgroundcolor='red', fontsize=8)\n",
    "        \n",
    "        axs[i].set_title(f\"Image {i+1}\")\n",
    "        axs[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Creation and Training\n",
    "\n",
    "Now, let's create and train our object detection model. We'll use a Faster R-CNN model with a ResNet50 backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create model trainer\n",
    "trainer = ModelTrainer(\n",
    "    model_type=\"faster_rcnn\",\n",
    "    backbone_name=\"resnet50\",\n",
    "    num_classes=91,  # COCO dataset has 90 classes + background\n",
    "    learning_rate=0.001,\n",
    "    batch_size=4,\n",
    "    num_epochs=10,  # Small number of epochs for demonstration\n",
    "    checkpoint_dir=project_root / \"checkpoints\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "print(f\"Model: {trainer.model_type} with {trainer.backbone_name} backbone\")\n",
    "print(f\"Number of classes: {trainer.num_classes}\")\n",
    "print(f\"Training device: {trainer.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Now let's train our model. This will take some time, especially if you're training on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "# Note: In a real scenario, you would train for more epochs\n",
    "if 'train' in dataloaders:\n",
    "    metrics = trainer.train(\n",
    "        train_dataloader=dataloaders['train'],\n",
    "        val_dataloader=dataloaders.get('val')\n",
    "    )\n",
    "    \n",
    "    # Plot training metrics\n",
    "    plot_training_metrics(metrics, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation\n",
    "\n",
    "Let's evaluate our trained model on the test dataset to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create predictor with the best model\n",
    "best_model_path = project_root / \"checkpoints\" / \"best_model.pth\"\n",
    "if best_model_path.exists():\n",
    "    predictor = Predictor(\n",
    "        model_path=best_model_path,\n",
    "        device=device,\n",
    "        confidence_threshold=0.5\n",
    "    )\n",
    "    \n",
    "    # Evaluate on test dataset\n",
    "    if 'test' in dataloaders:\n",
    "        # Initialize metrics\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        # Process each batch\n",
    "        for batch in dataloaders['test']:\n",
    "            # Get images and targets\n",
    "            images = batch[\"images\"].cpu().numpy()\n",
    "            targets = batch[\"targets\"]\n",
    "            \n",
    "            # Make predictions\n",
    "            batch_predictions = []\n",
    "            for i in range(len(images)):\n",
    "                # Convert image from CHW to HWC format\n",
    "                image = np.transpose(images[i], (1, 2, 0))\n",
    "                \n",
    "                # Denormalize image\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                image = (image * std + mean) * 255.0\n",
    "                image = image.astype(np.uint8)\n",
    "                \n",
    "                # Make prediction\n",
    "                prediction = predictor.predict(image)\n",
    "                batch_predictions.append(prediction)\n",
    "            \n",
    "            # Store predictions and targets for mAP calculation\n",
    "            all_predictions.extend(batch_predictions)\n",
    "            all_targets.extend(targets)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        from src.utils.metrics import calculate_map, calculate_map_range\n",
    "        map_50 = calculate_map(all_predictions, all_targets, iou_threshold=0.5)\n",
    "        map_range = calculate_map_range(all_predictions, all_targets)\n",
    "        \n",
    "        print(f\"Evaluation Results:\")\n",
    "        print(f\"mAP@0.5: {map_50:.4f}\")\n",
    "        print(f\"mAP@[0.5:0.95]: {map_range:.4f}\")\n",
    "else:\n",
    "    print(\"No trained model found. Please train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Making Predictions\n",
    "\n",
    "Now let's use our trained model to make predictions on new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to load and preprocess an image\n",
    "def load_image(image_path):\n",
    "    import cv2\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "# Make predictions on sample images\n",
    "if best_model_path.exists():\n",
    "    # Get sample images\n",
    "    sample_images_dir = project_root / \"data\" / \"samples\"\n",
    "    if not sample_images_dir.exists():\n",
    "        os.makedirs(sample_images_dir, exist_ok=True)\n",
    "        print(f\"Please add sample images to {sample_images_dir}\")\n",
    "    else:\n",
    "        # Get all image files\n",
    "        image_extensions = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "        image_paths = []\n",
    "        for ext in image_extensions:\n",
    "            image_paths.extend(list(sample_images_dir.glob(f\"*{ext}\")))\n",
    "        \n",
    "        if image_paths:\n",
    "            # Process each image\n",
    "            for image_path in image_paths[:5]:  # Process up to 5 images\n",
    "                # Load image\n",
    "                image = load_image(image_path)\n",
    "                \n",
    "                # Make prediction\n",
    "                result = predictor.predict(image, return_visualization=True)\n",
    "                \n",
    "                # Display results\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.imshow(result[\"visualization\"])\n",
    "                plt.title(f\"Predictions for {image_path.name}\")\n",
    "                plt.axis('off')\n",
    "                plt.show()\n",
    "                \n",
    "                # Print detection results\n",
    "                print(f\"\\nDetections for {image_path.name}:\")\n",
    "                for i, (box, score, class_name) in enumerate(zip(result['boxes'], result['scores'], result['class_names'])):\n",
    "                    print(f\"  Object {i+1}: {class_name}, Score: {score:.2f}, Box: {box}\")\n",
    "        else:\n",
    "            print(f\"No sample images found in {sample_images_dir}\")\n",
    "else:\n",
    "    print(\"No trained model found. Please train the model first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Real-time Inference with Webcam\n",
    "\n",
    "If you have a webcam connected, you can run real-time object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def run_webcam_detection(predictor, confidence_threshold=0.5):\n",
    "    import cv2\n",
    "    \n",
    "    # Open webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Press 'q' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        # Read frame\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convert frame to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Make prediction\n",
    "        result = predictor.predict(frame_rgb, return_visualization=True)\n",
    "        \n",
    "        # Convert visualization back to BGR for display\n",
    "        visualization = cv2.cvtColor(result[\"visualization\"], cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Display result\n",
    "        cv2.imshow(\"Object Detection\", visualization)\n",
    "        \n",
    "        # Check for quit key\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Run webcam detection if model is available\n",
    "if best_model_path.exists():\n",
    "    # Uncomment the line below to run webcam detection\n",
    "    # run_webcam_detection(predictor, confidence_threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the VisionDetect framework for object detection tasks. We covered:\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Loading and preprocessing data\n",
    "3. Creating and training a model\n",
    "4. Evaluating model performance\n",
    "5. Making predictions on new images\n",
    "6. Running real-time inference with a webcam\n",
    "\n",
    "The VisionDetect framework provides a comprehensive solution for object detection tasks, with support for different models, backbones, and deployment options. It's designed to be modular, extensible, and easy to use, making it suitable for a wide range of computer vision applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
